# Approach Criteria Evidence
[Link to Attachment E Approach Criteria Evidence Template Mod 5 spreadsheet](Attachment E Approach Criteria Evidence Template Mod 5.xlsx)

|#|criteria |evidence #1|
|---|---------|-----------|
|a|assigned one leader, gave that person authority and responsibility, and held that person accountable for the quality of the prototype submitted | We assigned our [Product Manager (Ray R.)](docs/MedExplorer%20Development%20Team.md) and gave him the authority, responsibility, and accountability for the MedExplorer prototype. <BR><BR>__Digital Playbook #6__ Assign one leader and hold that person accountable" |
|b|assembled a multidisciplinary and collaborative team including a minimum of 5 labor categories from the Development Pool labor categories to design and develop the prototype | Our [MedExplorer development team](docs/MedExplorer%20Development%20Team.md) used 10 of the labor categories to design and develop the prototype. <BR><BR>__Digital Playbook #7__ Bring in experienced teams |
|c|understand what people need, by including people in the prototype development and design process | Our User Experience [design team interviewed](docs/User Centered Design/Research Findings) and performed user tests with a number for General Public and Clinician users. The team also met with Northrop Grumman's Clinical Advisory Group as part of our Health Division. Users participated in periodic demonstrations for feedback. Created [scenarios](docs/User Centered Design/Scenarios) and [stories](docs/Software Development/User-Stories). The team gave periodic demonstrations to walk through scenarios and gather feedback. We captured feedback as user stories and added to the backlog for prioritization. <BR><BR>__Digital Playbook #1__ Understand what people need |
|d|used at least three "human-centered design" techniques or tools | Our [User Centered Design](docs/User Centered Design/Readme.md) approach used a number of techniques and tools, including interviews, focus groups, expectancy tests, generative research, and usability tests. <BR><BR>__Digital Playbook #3__ Make it simple and intuitive |
|e|created or used a design style guide and/or a pattern library | Our UX team created a [design style guide](docs/User Centered Design/Design Style Guide/Style_Guide_Master.pdf) to provide guidance for the web front end developers. Style guides were updated each sprint with development. <BR><BR>__Digital Playbook #3__ Make it simple and intuitive |
|f|performed usability tests with people | Our UX team performed a number of [usability tests](docs/User Centered Design/Research Findings/Focus Group2.pdf) with users and [provided feedback](docs/User%20Centered%20Design/Research%20Findings/Generative_Research.pdf) to the development staff. Once we had some initial features in place, usuability tests were run daily. <BR><BR>__Digital Playbook #4__ Build the service using agile and iterative practices |
|g|used an iterative approach, where feedback informed subsequent work or versions of the prototype | Using our [Agile framework](docs/Software Development/Processes/Readme.md), which is built upon Scrum, Extreme Programming, and [user-centered design](docs/User Centered Design/Readme.md) techniques, we were able to develop the product in an [iterative fashion](docs/Software Development/Iterative Development.md) while receiving regular, [timely feedback](docs/User%20Centered%20Design/Research%20Findings/Generative_Research.pdf) from users and stakeholders. We conducted an initial sprint 0 as we identifed the team and coordinated the infrastructure. Then we used sprint cycles of 5 hours each comprised of sprint planning, execution, and review (demo and retrospective). <BR><BR>__Digital Playbook #4__ Build the service using agile and iterative practices |
|h|created a prototype that works on multiple devices, and presents a responsive design | Our MedExplorer prototype was designed for [multiple platforms] (docs/Software Development/Platform Support.md) including PCs, laptops, tablets, and phones. <BR><BR>__Digital Playbook #2__ Address the whole experience, from start to finish <BR>__Digital Playbook #7__ Bring in experienced teams |
|i|used at least five modern and open-source technologies, regardless of architectural layer (frontend, backend, etc.) | Our MedExplorer used a number for modern, [open source](/License.md#open-source-third-party-software-licenses) technologies, including TwitterBootstrap, AngularJS, NodeJS, ExpressJS, Docker, MongoDB, Jenkins and Zabbix. As shown in our [technology stack diagram](docs/Diagrams/MedExplorer_TechnologyStack.png). <BR><BR>__Digital Playbook #8__ Choose a modern technology stack |
|j|deployed the prototype on an Infrastructure as a Service (IaaS) or Platform as a Service (PaaS) provider, and indicated which provider they used | Our [MedExplorer prototype](http://MedExplorer.northropgrumman.com) is deployed on a IaaS provider, we selected [IBM SoftLayer](docs/Software Development/Screenshots/softlayer.png) as our provider. <BR><BR>__Digital Playbook #9__ Deploy in a flexible hosting environment |
|k|wrote unit tests for their code | Our development wrote [unit tests](src/client/test) for their code and was part of the team's [definition of done](docs/Pictures/Definition of Done.jpg). The front-end unit testing is done using the Jasmine testing framework, which is run by the Karma test-runner. The back-end code is tested using the UnitJS testing framework and is run by mocha. These [unit tests were automated using Jenkins] (docs/Software%20Development/Processes/DevOps.md#unit-testing-and-automated-test) so that they run after every commit. <BR><BR>__Digital Playbook #10__ Automate testing and deployments |
|l|set up or used a continuous integration system to automate the running of tests and continuously deployed their code to their IaaS or PaaS provider | Our development team used [Jenkins](docs/Software%20Development/Screenshots#jenkins) for our [continuous integration](docs/Software%20Development/Processes/DevOps.md#continuous-integration) system to automate running of tests and to perform continuous deployment. <BR><BR>__Digital Playbook #10__ Automate testing and deployments |
|m|set up or used configuration management | We used an internal [GitHub Enterprise](docs/Software%20Development/Screenshots#github) server as our configuration management systems. <BR><BR>__Digital Playbook #4__ Build the service using agile and iterative practices |
|n|set up or used continuous monitoring | We setup and used [Zabbix](http://medexplorer.northropgrumman.com:9001/zabbix/dashboard.php) to perform continuous monitoring of our development/test environment and our production environment. <BR><BR>__Digital Playbook #12__ Use data to drive decisions |
|o|deploy their software in a container (i.e., utilized operating-system-level virtualization) | We used [Docker](docs/Software%20Development/Processes/DevOps.md#continuous-deliverydeployment) as our container system for our MedExplorer prototype. <BR><BR>__Digital Playbook #4__ Build the service using agile and iterative practices <BR>__Digital Playbook #9__ Deploy in a flexible hosting environment |
|p|provided sufficient documentation to install and run their prototype on another machine | We have provided [instructions](docs/Install%20Procedures) for installing MedExplorer in your own Docker container system. <BR><BR>__Digital Playbook #9__ Deploy in a flexible hosting environment |
|q|prototype and underlying platforms used to create and run the prototype are openly licensed and free of charge | The MedExplorer prototype and underlying platforms, components, and frameworks used on the project were [open source licensed](License.md) and free of charge. <BR><BR>__Digital Playbook #13__ Default to open |